record_video: yes
seed: 2

environment:
  seed: 2
  render: True
  num_envs: 1
  eval_every_n: 200
  num_threads: 30
  simulation_dt: 0.001
  control_dt: 0.5
  low_level_control_dt: 0.005
  max_time: 8.0
  reward:
    commandRewardCoeff_: -5e-3
    joint_velocity_reward_coeff: -10e-1
    slip_reward_coeff: -3e-2
    airtime_reward_coeff: 0e-1
    smooth_reward_coeff: -2
    con_switch_rew_coeff: -50
    torque_reward_coeff: -5e-2
    orientation_reward_coeff: -800
    towardObjectRewardCoeff_: 1
    stayObjectRewardCoeff_: 10
    towardTargetRewardCoeff_: 2
    stayTargetRewardCoeff_: 20
  curriculum:
    initial_factor: .2
    decay_factor: 0.97
  hierarchical: True
  architecture:
    actor: [1, 1, 1, 1, 1]
    estimator: [1, 1, 1, 1, 1]



architecture:
  policy_net: [256, 128]
  value_net: [256, 128]
