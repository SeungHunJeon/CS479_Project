record_video: no
seed: 2

environment:
  seed: 2
  render: True
  num_envs: 100
  eval_every_n: 200
  num_threads: 30
  simulation_dt: 0.00025
  control_dt: 0.1
  low_level_control_dt: 0.01
  max_time: 10.0
  reward:
    command_tracking_reward_coeff: 600
    joint_velocity_reward_coeff: -10e-1
    slip_reward_coeff: -3e-2
    airtime_reward_coeff: 0e-1
    smooth_reward_coeff: -2
    con_switch_rew_coeff: -50
    torque_reward_coeff: -5e-2
    orientation_reward_coeff: -800
    towardObjectRewardCoeff_: 100
    stayObjectRewardCoeff_: 1500
    towardTargetRewardCoeff_: 200
    stayTargetRewardCoeff_: 1000
  curriculum:
    initial_factor: .2
    decay_factor: 0.97
  hierarchical: True
  architecture:
    actor: [1, 1, 1, 1, 1]
    estimator: [1, 1, 1, 1, 1]



architecture:
  policy_net: [256, 128]
  value_net: [256, 128]
