record_video: no
seed: 2

environment:
  discrete_action: False
  seed: 2
  render: True
  num_envs: 300
  eval_every_n: 200
  num_threads: 30
  simulation_dt: 0.001
  control_dt: 0.25
  low_level_control_dt: 0.005
  max_time: 10.0
  entropy_coeff: 1e-3
  discrete:
    radial: 1
    tangential: 72
  reward:
#    commandRewardCoeff_: 1e-1
    commandRewardCoeff_: 0
    torque_reward_coeff: -6e-3
#    torque_reward_coeff: 0
    towardObjectRewardCoeff_: 1
    stayObjectRewardCoeff_: 2
    towardTargetRewardCoeff_: 1
    stayTargetRewardCoeff_: 3
    stayObjectHeadingRewardCoeff_ : 1
  curriculum:
    initial_factor: .2
    decay_factor: 0.97
  hierarchical: True
  dimension:
    proprioceptiveDim_: 9
    exteroceptiveDim_: 43
    inertialparamDim_: 15
    dynamicsDim_: 2
    historyNum_: 5
    actionhistoryNum_: 6
    actionDim_: 2

  ROA_dimension:
    exteroceptiveDim_: 28

encoder:
  proprioceptivelatentDim_: 16
  exteroceptivelatentDim_: 32
  actionlatentDim_: 4

LSTM:
  is_decouple_: False
  hiddendim_: 52
  batchNum_: 1

architecture:
  policy_net: [256, 128, 64]
  value_net: [256, 128, 64]

  encoding:
    policy_net: [ 128, 64 ]
    value_net: [ 128, 64 ]
    pro_encoder_net: [128, 64] # 9 x 4
    ext_encoder_net: [256, 128, 64] # 25 x 4
    act_encoder_net: [32, 32] # 2 x 4

  estimator:
    net: [64, 64]

  obj_f_dynamics:
    net: [256, 128, 64]

  obs_f_dynamics:
    net: [256, 128]