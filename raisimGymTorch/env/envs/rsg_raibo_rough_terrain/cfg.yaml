record_video: no
seed: 2

environment:
  seed: 2
  render: True
  num_envs: 500
  eval_every_n: 200
  num_threads: 30
  simulation_dt: 0.001
  control_dt: 0.5
  low_level_control_dt: 0.005
  max_time: 8.0
  reward:
#    commandRewardCoeff_: -5e-5
    commandRewardCoeff_: 0
    joint_velocity_reward_coeff: -10e-1
    slip_reward_coeff: -3e-2
    airtime_reward_coeff: 0e-1
    smooth_reward_coeff: -2
    con_switch_rew_coeff: -50
    torque_reward_coeff: -5e-2
    orientation_reward_coeff: -800
    towardObjectRewardCoeff_: 1
    stayObjectRewardCoeff_: 2
    towardTargetRewardCoeff_: 1
    stayTargetRewardCoeff_: 2
  curriculum:
    initial_factor: .2
    decay_factor: 0.97
  hierarchical: True
  architecture:
    actor: [1, 1, 1, 1, 1]
    estimator: [1, 1, 1, 1, 1]



architecture:
  policy_net: [128, 64]
  value_net: [128, 64]
