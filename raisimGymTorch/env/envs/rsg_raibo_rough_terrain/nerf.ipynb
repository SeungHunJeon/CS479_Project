{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import argparse\n",
    "from estimator_helper import state_estimator, get_img_process\n",
    "from nerf_helper import load_intrinsic_params\n",
    "from nerf.utils import *\n",
    "from nav.math_utils import vec_to_rot_matrix, rot_matrix_to_vec\n",
    "from nerf.provider import NeRFDataset\n",
    "from nav.planner_helper import Planner\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.weight = None\n",
    "        self.path = 'data/nerf_synthetic/custom_8'  # Set default path\n",
    "        self.O = True\n",
    "        self.test = False\n",
    "        self.workspace = 'trial_nerf_custom_8'\n",
    "        self.seed = 0\n",
    "\n",
    "        # Training options\n",
    "        self.iters = 30000\n",
    "        self.lr = 1e-2\n",
    "        self.ckpt = 'latest'\n",
    "        self.num_rays = 4096\n",
    "        self.cuda_ray = False\n",
    "        self.max_steps = 1024\n",
    "        self.num_steps = 512\n",
    "        self.upsample_steps = 0\n",
    "        self.update_extra_interval = 16\n",
    "        self.max_ray_batch = 4096\n",
    "\n",
    "        # Network backbone options\n",
    "        self.fp16 = False\n",
    "        self.ff = False\n",
    "        self.tcnn = False\n",
    "\n",
    "        # Dataset options\n",
    "        self.color_space = 'srgb'\n",
    "        self.preload = False\n",
    "        self.bound = 5.0\n",
    "        self.scale = 0.33\n",
    "        self.offset = [0, 0, 0]\n",
    "        self.dt_gamma = 0.02\n",
    "        self.min_near = 0.2\n",
    "        self.density_thresh = 10\n",
    "        self.bg_radius = -1\n",
    "\n",
    "        # GUI options\n",
    "        self.gui = False\n",
    "        self.W = 1920\n",
    "        self.H = 1080\n",
    "        self.radius = 5\n",
    "        self.fovy = 50\n",
    "        self.max_spp = 64\n",
    "\n",
    "        # Experimental\n",
    "        self.error_map = False\n",
    "        self.clip_text = ''\n",
    "        self.rand_pose = -1\n",
    "\n",
    "        # Additional configurations based on conditional logic\n",
    "        self.path = os.getcwd() + \"/\" + self.path\n",
    "        self.workspace = os.getcwd() + \"/\" + self.workspace\n",
    "        if self.O:\n",
    "            self.fp16 = True\n",
    "            self.cuda_ray = False\n",
    "            self.preload = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('tkagg')\n",
    "device = torch.device('cuda:0')\n",
    "# Configuration\n",
    "\n",
    "# file_path = os.path.dirname()\n",
    "# Create a config instance\n",
    "opt = Config()\n",
    "if opt.ff:\n",
    "    opt.fp16 = False\n",
    "    assert opt.bg_radius <= 0, \"background model is not implemented for --ff\"\n",
    "    # Specific import for ff\n",
    "    from nerf.network_ff import NeRFNetwork\n",
    "elif opt.tcnn:\n",
    "    opt.fp16 = False\n",
    "    assert opt.bg_radius <= 0, \"background model is not implemented for --tcnn\"\n",
    "    # Specific import for tcnn\n",
    "    from nerf.network_tcnn import NeRFNetwork\n",
    "else:\n",
    "    # Default import if neither ff nor tcnn\n",
    "    from nerf.network import NeRFNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(opt.seed)\n",
    "\n",
    "nerf_model = NeRFNetwork(\n",
    "    encoding=\"hashgrid\",\n",
    "    bound=opt.bound,\n",
    "    cuda_ray=opt.cuda_ray,\n",
    "    density_scale=1,\n",
    "    min_near=opt.min_near,\n",
    "    density_thresh=opt.density_thresh,\n",
    "    bg_radius=opt.bg_radius,\n",
    ")\n",
    "\n",
    "nerf_model.eval()\n",
    "metrics = [PSNRMeter(),]\n",
    "intrinsics, img_W, img_H = load_intrinsic_params(opt)\n",
    "nerf_model = nerf_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Latest checkpoint is /home/oem/workspace/raibo_arm/raisimGymTorch/env/envs/rsg_raibo_rough_terrain/trial_nerf_custom_8/checkpoints/ngp_ep0001.pth\n",
      "[INFO] loaded model.\n",
      "[WARN] unexpected keys: ['density_grid', 'density_bitfield', 'step_counter']\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = os.path.join(opt.workspace, 'checkpoints')\n",
    "checkpoint = None\n",
    "if checkpoint is None:\n",
    "    checkpoint_list = sorted(glob.glob(f'{ckpt_path}/ngp_ep*.pth'))\n",
    "if checkpoint_list:\n",
    "    checkpoint = checkpoint_list[-1]\n",
    "    print(f\"[INFO] Latest checkpoint is {checkpoint}\")\n",
    "else:\n",
    "    print(\"[WARN] No checkpoint found, model randomly initialized.\")\n",
    "\n",
    "checkpoint_dict = torch.load(checkpoint, map_location='cpu')\n",
    "if 'model' not in checkpoint_dict:\n",
    "    nerf_model.load_state_dict(checkpoint_dict)\n",
    "    print(\"[INFO] loaded model.\")\n",
    "\n",
    "else:\n",
    "    missing_keys, unexpected_keys = nerf_model.load_state_dict(checkpoint_dict['model'], strict=False)\n",
    "    print(\"[INFO] loaded model.\")\n",
    "    if len(missing_keys) > 0:\n",
    "        print(f\"[WARN] missing keys: {missing_keys}\")\n",
    "    if len(unexpected_keys) > 0:\n",
    "        print(f\"[WARN] unexpected keys: {unexpected_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], device=device, dtype=torch.float32)\n",
    "density_fn = lambda x: nerf_model.density(x.reshape((-1, 3)) @ rot)['sigma'].reshape(x.shape[:-1])\n",
    "render_fn = lambda rays_o, rays_d: nerf_model.render(rays_o, rays_d, staged=True, bg_color=1., perturb=False, **vars(opt))\n",
    "get_rays_fn = lambda pose: get_rays(pose, intrinsics, img_H, img_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 7.78 GiB total capacity; 4.36 GiB already allocated; 114.19 MiB free; 4.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m new_pose \u001b[38;5;241m=\u001b[39m new_pose\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m rays \u001b[38;5;241m=\u001b[39m get_rays_fn(new_pose\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)))\n\u001b[0;32m----> 8\u001b[0m \u001b[43mrender_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrays_o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrays_d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(rays_o, rays_d)\u001b[0m\n\u001b[1;32m      1\u001b[0m rot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m], [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m], [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m]], device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      2\u001b[0m density_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: nerf_model\u001b[38;5;241m.\u001b[39mdensity(x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)) \u001b[38;5;241m@\u001b[39m rot)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m render_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m rays_o, rays_d: \u001b[43mnerf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrays_o\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrays_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstaged\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbg_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m get_rays_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m pose: get_rays(pose, intrinsics, img_H, img_W)\n",
      "File \u001b[0;32m~/workspace/raibo_arm/raisimGymTorch/env/envs/rsg_raibo_rough_terrain/nerf/renderer.py:563\u001b[0m, in \u001b[0;36mNeRFRenderer.render\u001b[0;34m(self, rays_o, rays_d, staged, max_ray_batch, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m head \u001b[38;5;241m<\u001b[39m N:\n\u001b[1;32m    562\u001b[0m     tail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(head \u001b[38;5;241m+\u001b[39m max_ray_batch, N)\n\u001b[0;32m--> 563\u001b[0m     results_ \u001b[38;5;241m=\u001b[39m \u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrays_o\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrays_d\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m     depth[b:b\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, head:tail] \u001b[38;5;241m=\u001b[39m results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    565\u001b[0m     image[b:b\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, head:tail] \u001b[38;5;241m=\u001b[39m results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/raibo_arm/raisimGymTorch/env/envs/rsg_raibo_rough_terrain/nerf/renderer.py:165\u001b[0m, in \u001b[0;36mNeRFRenderer.run\u001b[0;34m(self, rays_o, rays_d, num_steps, upsample_steps, bg_color, perturb, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m xyzs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(torch\u001b[38;5;241m.\u001b[39mmax(xyzs, aabb[:\u001b[38;5;241m3\u001b[39m]), aabb[\u001b[38;5;241m3\u001b[39m:]) \u001b[38;5;66;03m# a manual clip.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m#plot_pointcloud(xyzs.reshape(-1, 3).detach().cpu().numpy())\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# query SDF and RGB\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m density_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdensity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyzs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m#sigmas = density_outputs['sigma'].view(N, num_steps) # [N, T]\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m density_outputs\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/workspace/raibo_arm/raisimGymTorch/env/envs/rsg_raibo_rough_terrain/nerf/network.py:132\u001b[0m, in \u001b[0;36mNeRFNetwork.density\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    130\u001b[0m h \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m--> 132\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma_net\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    134\u001b[0m         h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(h, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-ngp/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-ngp/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 7.78 GiB total capacity; 4.36 GiB already allocated; 114.19 MiB free; 4.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "new_pose = torch.eye(4)\n",
    "new_pose[:3, :3] = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], device=device, dtype=torch.float32)\n",
    "new_pose[:3, 3] = torch.tensor([0., 0., 0.5], device=device, dtype=torch.float32)\n",
    "new_pose = new_pose.to(device)\n",
    "\n",
    "rays = get_rays_fn(new_pose.reshape((1,4,4)))\n",
    "\n",
    "render_fn(rays[\"rays_o\"].reshape((img_H, img_W, -1)), rays[\"rays_d\"].reshape((img_H, img_W, -1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raisimLib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f2922adba999d1398fcf6364e1079a6f710ff4cac48f8f8ea80d633b3aa6b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
